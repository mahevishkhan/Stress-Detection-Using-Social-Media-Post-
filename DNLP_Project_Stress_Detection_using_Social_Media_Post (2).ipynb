{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stress Detection using ML\n",
        "\n",
        "> Stress is a common experience that can have a negative impact on our mental and physical health. It is important to be able to identify stress and take steps to manage it. However, it can be difficult to identify stress, especially if it is chronic or low-level.\n",
        "\n",
        "*  Social media platforms provide a unique opportunity to detect stress. People often share their feelings and experiences on social media, including their feelings of stress. By analyzing social media posts, it is possible to identify patterns that indicate stress.\n",
        "*    In this project, we will develop a machine learning model to detect stress from social media posts. We will use a dataset of Reddit posts that are labeled as either \"stressed\" or \"not stressed\". We will train a model to identify the features of social media posts that are associated with stress.\n",
        "*  Once the model is trained, we can use it to identify social media users who may be stressed. This information can be used to provide support to these users or to develop interventions to reduce stress.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XVv6TQVBsibe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary libraries:"
      ],
      "metadata": {
        "id": "lGQZsGLYseln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxgiAdZyk7NM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset:"
      ],
      "metadata": {
        "id": "C4JEOSNtxq4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/Stress.csv\")"
      ],
      "metadata": {
        "id": "8FQsC4xRxs_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "A8vaP4LJyNES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stopword = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text = \" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGsNfapsyQPu",
        "outputId": "5cae110a-8a7b-4c8c-c4c6-1cbbb5f2d8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create features and labels"
      ],
      "metadata": {
        "id": "y_e_3Q8ryXjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"text\"] = data[\"text\"].apply(clean_text)\n",
        "x = np.array(data[\"text\"])\n",
        "y = np.array(data[\"label\"])"
      ],
      "metadata": {
        "id": "-GEmELFlyaf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize text data"
      ],
      "metadata": {
        "id": "6tas0gV8yejl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x)"
      ],
      "metadata": {
        "id": "lxwOBb2qyira"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into training and testing sets"
      ],
      "metadata": {
        "id": "YtZottfnynEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
      ],
      "metadata": {
        "id": "72rJsQ7Gyp9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Bernoulli Naive Bayes model\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "NO67CYmNywQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BernoulliNB()\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ys-jWq9Mjqpv",
        "outputId": "969f5b14-2219-4774-ae9c-adfd71ec4e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy"
      ],
      "metadata": {
        "id": "N57omywBkUqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = model.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg5S4QJUjuyG",
        "outputId": "38708b18-e11e-4143-a50a-2cb81a161d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 74.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Classification Report"
      ],
      "metadata": {
        "id": "m8UEGp2DkJOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOXlmtkSj8lY",
        "outputId": "550058db-f691-4808-d397-d6f679344f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.64      0.70       444\n",
            "           1       0.72      0.85      0.78       493\n",
            "\n",
            "    accuracy                           0.75       937\n",
            "   macro avg       0.75      0.74      0.74       937\n",
            "weighted avg       0.75      0.75      0.74       937\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model with user input and also Predicting the Output\n"
      ],
      "metadata": {
        "id": "mfrrrLrsy2k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on user input\n",
        "user_input = input(\"Enter a text: \")\n",
        "user_data = cv.transform([user_input]).toarray()\n",
        "prediction = model.predict(user_data)\n",
        "\n",
        "def fun(prediction):\n",
        "    if prediction == 1:\n",
        "        return \"Stress\"\n",
        "    else:\n",
        "        return \"No Stress\"\n",
        "\n",
        "print(\"Detected:\", fun(prediction[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP-8qYJ3zC3_",
        "outputId": "31464845-6b16-4150-dd22-45d0f17f30bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a text: I'm so used to being forced to submit to him that I no longer have a voice. He heavily favors my sister over me and would buy her anything she wanted in a heartbeat. An example would be at Darvin furniture one time. He takes me and my sister there and tells her to pick out a desk. I look at a $100 discount desk and he says we don't have enough money.\n",
            "Detected: No Stress\n"
          ]
        }
      ]
    }
  ]
}